---
title: "Research"
permalink: /research/
author_profile: true
---

<style>
table {border:0;}
tr {border:0;}
td {border:0;}
</style>

<style>

.project_description {
  text-align: justify;
  vertical-align: text-top;
}

.project_title {
  text-align: left;
  font-weight: bold;
  background-color: lightblue;
}

.project_duration {
  text-align: right;
  font-weight: bold;
  background-color: lightblue;
}

.project_video
{
  vertical-align:top;
}

</style>

<table style="width:100%;">
  <col width="30%">
  <col width="70%">


	<tr>
    <td class = "project_duration"> Sep 2019 - present </td>
    <td class = "project_title">  Autonomy Capabilities for Commercial Aircrafts </td> 
  </tr>
       
  <tr>
    <td class = "project_video"> <img src="/images/airbus_runway_detection.gif" alt="Airbus Aircrafts" width = "400px" /> </td>
    <td class = "project_description"> I work on the perception software for various autonomy projects such as autonomous detect and avoid for drones, runway detection for autonomous taxi, take-of and landing,certification of perception algorithms. I deploy machine learning models (deep learning) on embedded computing platforms (CUDA, Nvidia GPUs) for end-to-end inference.
    </td>
  </tr>
	
  <tr>
    <td class = "project_duration"> May 2018 - June 2019 </td>
    <td class = "project_title">  Planning and Controls For Self-Driving Cars </td> 
  </tr>

  <tr >
    <td class = "project_video"> <img src="/images/tesla_autopilot.gif" alt="Tesla Autopilot" width = "400px" /> </td>
    <td class = "project_description"> Tesla Autopilot is an advanced driving system that enables your car to steer, accelerate and brake automatically within its lane, automatically steers your vehicle toward highway interchanges and exits based on your destination. Also, with the latest Smart Summon feature, your car can navigate more complex environments and parking spaces, maneuvering around objects as necessary to come find you in a parking lot.
    <br>
		<br>
    As a member of the Planning and Control team, I contributed to the following features:
		<ul>
      <li>development of the Navigate on Autopilot and Smart Summon features</li>
      <li>implemnetation of the decision software for traffic-aware safe lane change, merging to on-ramp, off-ramp cases in high-speed highway driving.</li>
      <li>implementation of the path planner for the enhanced summon feature to navigate in unstructured environments among moving objects (pedestrians, vehicles, etc).</li>
      <li>release of the production codes for autopilot software and performing drive tests on a daily basis</li>
     </ul>
    </td>
  </tr>

  <tr >
    <td class = "project_duration"> Oct 2015 - Oct 2017 </td>
    <td class = "project_title"> Autonomous Mapping of Small-bodies in Space</td>
  </tr>

  <tr>
    <td class = "project_video" > <img src="/images/nasa_jpl_autonomous_mapping_of_small_bodies.gif" alt="NASA JPL Autonomous Mapping of Small-bodies in Space" width = "400px" />  </td>
    <td class = "project_description">
      The objective was to develop autonomous decision making capabilities for a spacecraft for exploration and mapping of unknown small bodies in space. 
      <br>
      <br>
      I contributed to development of a high-fidelity, physics-based spacecraft model and integrated NASA JPL spacecraft GNC flight software to the simulated model for software-in-the-loop testing of mission scenarios.
    </td>
  </tr>



  <tr >
    <td class = "project_duration"> Oct 2015 - Oct 2017 </td>
    <td class = "project_title"> Autonomous Robotic Inspection of Tanks</td>
  </tr>

  <tr>
    <td class = "project_video" > <img src="/images/nasa_jpl_robotic_inspection_of_tanks.jpg" alt="NASA JPL Robotic Inspection of Tanks" width = "400px" />  </td>
    <td class = "project_description">
      The objective was to develop quadrotors that use 3D imaging technology to help engineers pinpoint and assess structural damage, oil leakages, and other weaknesses in large fuel tankers in offshore seas. 
      <br>
      <br>
      I implemented the autonomous exploration and navigation stack (ROS) for quadrotors, which uses frontier-based exploration strategy, sampling-based planners for pointto-point navigation and dynamic programming based algorithms for collision avoidance in unstructured environments.
    </td>
  </tr>


  <tr >
    <td class = "project_duration"> Oct 2015 - Oct 2017 </td>
    <td class = "project_title"> Next-Gen Autonomous Navigation for Future Mars Rovers</td>
  </tr>
  <tr>
    <td class = "project_video" > <img src="/images/nasa_jpl_mars_rover.gif" alt="NASA JPL Mars Rover" width = "400px" />  </td>
    <td class = "project_description">
      The objective was to develop state-of-the-art motion planners for navigation of Mars rovers. 
      <br>
      <br>
      I worked on implementation of a sampling-based motion planner (RRT with closed-loop prediction) which utilizes kinematic rover model for generation of smooth trajectories. The final navigation stack was successfully tested on a Mars Rover platform. 
      <a href="https://www.youtube.com/watch?v=avLIZBnT8SE">demo</a>
    </td>
  </tr>


   
  <tr>
    <td class = "project_duration"> Aug 2014 - May 2015 </td>
    <td class = "project_title"> Route Planning for Full-scale Helicopters </td>
  </tr>

  <tr>
    <td class = "project_video" > <img src="/images/aurora_flight_sciences_helicopter.gif" alt="Boeing Little Bird" width = "400px" />  </td>
    <td class = "project_description">
      The Autonomous Aerial Cargo Utility System (AACUS) was a five-year, <span>&dollar;</span>98 million program announced by the Office of Naval Research (ONR) to develop advanced autonomous capabilities for reliable resupply/retrograde by a robotic VTOL air vehicle under adverse conditions. 
      <br>
      <br>
      I designed and implemented the high-level route planner for the autonomous helicopter and helped the GNC engineers for integration to flight software. Our team won a <span>&dollar;</span>13.7 million contract for the Phase II of the development, against competition from Lockheed Martin. 
      <a href="https://www.flightglobal.com/news/articles/aurora-beats-lockheed-bid-to-develop-ipad-based-uas-398947/">press</a>
      <a href="https://www.youtube.com/watch?v=vfuHNHLJzoM">demo</a>
    </td>
  </tr>


  <tr>
    <td class = "project_duration"> Aug 2011 - Sep 2015 </td>
    <td class = "project_title"> Optimal Sampling-based Motion Planning for Aggressive Mobility</td>
  </tr>

  <tr>
    <td class = "project_video" > <img src="/images/gatech_aggressive_mobility.gif" alt="Aggressive Mobility" width = "400px" />  </td>
    <td class = "project_description">
      The objective was to develop new algorithms for real-time perception, navigation and control of highly-maneuverable, autonomous and semi-autonomous (primarily, ground) vehicles operating at high speed and at the limits their performance envelope. The inspiration comes from human cognitive (decision) and execution (control) models, especially those of expert human race drivers. <a href="http://amav.gatech.edu/">details</a>
      <br>
      <br>
      I developed a new incremental sampling-based algorithm, which utilizes ideas from rapidlyexploring random graphs, dynamic programming and relaxation algorithms, for optimal motion planning and worked on a parallel implementation of the algorithm and trajectory generation for aggressive maneuvers of autonomous ground vehicle.
    </td>
  </tr>

</table>


